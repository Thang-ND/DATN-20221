version: '3'

services:

# Set up hadoop cluster which includes 3 node (1 namenode and 2 datanodes)

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    ports: 
      - "9870:9870"
      - "9000:9000"
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=thangnd-hust
    env_file:
      - ./hadoop.env
  
  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
  
  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
  #  restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 datanode2:9864"
    env_file:
      - ./hadoop.env

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager1
 #   restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
  
  nodemanager2:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager2
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode2:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
#    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 datanode2:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
  
# Set up spark cluster includes 3 node and jupyterlab

  jupyterlab:
    image: andreper/jupyterlab:3.0.0-spark-3.0.0
    container_name: jupyterlab
    ports:
      - 8889:8888
      - 4044:4040
    volumes:
      - shared-workspace:/opt/workspace

  spark-master:
    image: andreper/spark-master:3.0.0
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
      - 4040:4040
    volumes:
      - shared-workspace:/opt/workspace

  spark-worker-1:
    image: andreper/spark-worker:3.0.0
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1024m
    ports:
      - 8081:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
  spark-worker-2:
    image: andreper/spark-worker:3.0.0
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1024m
    ports:
      - 8082:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master

# Elastic search and Kibana setup
  # setup:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #   user: "0"
  #   command: >
  #     bash -c '
  #       if [ x${ELASTIC_PASSWORD} == x ]; then
  #         echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
  #         exit 1;
  #       elif [ x${KIBANA_PASSWORD} == x ]; then
  #         echo "Set the KIBANA_PASSWORD environment variable in the .env file";
  #         exit 1;
  #       fi;
  #       if [ ! -f config/certs/ca.zip ]; then
  #         echo "Creating CA";
  #         bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
  #         unzip config/certs/ca.zip -d config/certs;
  #       fi;
  #       if [ ! -f config/certs/certs.zip ]; then
  #         echo "Creating certs";
  #         echo -ne \
  #         "instances:\n"\
  #         "  - name: es01\n"\
  #         "    dns:\n"\
  #         "      - es01\n"\
  #         "      - localhost\n"\
  #         "    ip:\n"\
  #         "      - 127.0.0.1\n"\
  #         "  - name: es02\n"\
  #         "    dns:\n"\
  #         "      - es02\n"\
  #         "      - localhost\n"\
  #         "    ip:\n"\
  #         "      - 127.0.0.1\n"\
  #         > config/certs/instances.yml;
  #         bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
  #         unzip config/certs/certs.zip -d config/certs;
  #       fi;
  #       echo "Setting file permissions"
  #       chown -R root:root config/certs;
  #       find . -type d -exec chmod 750 \{\} \;;
  #       find . -type f -exec chmod 640 \{\} \;;
  #       echo "Waiting for Elasticsearch availability";
  #       until curl -s --cacert config/certs/ca/ca.crt https://es01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
  #       echo "Setting kibana_system password";
  #       until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
  #       echo "All done!";
  #     '
  #   healthcheck:
  #     test: ["CMD-SHELL", "[ -f config/certs/es01/es01.crt ]"]
  #     interval: 1s
  #     timeout: 5s
  #     retries: 120

  # es01:
  #   container_name: es01
  #   depends_on:
  #     setup:
  #       condition: service_healthy
  #   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #     - esdata01:/usr/share/elasticsearch/data
  #   ports:
  #     - 9200:9200
  #   environment:
  #     - node.name=es01
  #     - cluster.name=${CLUSTER_NAME}
  #     - cluster.initial_master_nodes=es01,es02
  #     - discovery.seed_hosts=es02
  #     - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
  #     - bootstrap.memory_lock=true
  #     - xpack.security.enabled=true
  #     - xpack.security.http.ssl.enabled=true
  #     - xpack.security.http.ssl.key=certs/es01/es01.key
  #     - xpack.security.http.ssl.certificate=certs/es01/es01.crt
  #     - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.http.ssl.verification_mode=certificate
  #     - xpack.security.transport.ssl.enabled=true
  #     - xpack.security.transport.ssl.key=certs/es01/es01.key
  #     - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
  #     - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.transport.ssl.verification_mode=certificate
  #     - xpack.license.self_generated.type=${LICENSE}
  #   mem_limit: ${MEM_LIMIT}
  #   ulimits:
  #     memlock:
  #       soft: -1
  #       hard: -1
  #   healthcheck:
  #     test:
  #       [
  #         "CMD-SHELL",
  #         "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
  #       ]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 120

  # es02:
  #   container_name: es02
  #   depends_on:
  #     - es01
  #   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #     - esdata02:/usr/share/elasticsearch/data
  #   environment:
  #     - node.name=es02
  #     - cluster.name=${CLUSTER_NAME}
  #     - cluster.initial_master_nodes=es01,es02
  #     - discovery.seed_hosts=es01
  #     - bootstrap.memory_lock=true
  #     - xpack.security.enabled=true
  #     - xpack.security.http.ssl.enabled=true
  #     - xpack.security.http.ssl.key=certs/es02/es02.key
  #     - xpack.security.http.ssl.certificate=certs/es02/es02.crt
  #     - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.http.ssl.verification_mode=certificate
  #     - xpack.security.transport.ssl.enabled=true
  #     - xpack.security.transport.ssl.key=certs/es02/es02.key
  #     - xpack.security.transport.ssl.certificate=certs/es02/es02.crt
  #     - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.transport.ssl.verification_mode=certificate
  #     - xpack.license.self_generated.type=${LICENSE}
  #   mem_limit: ${MEM_LIMIT}
  #   ulimits:
  #     memlock:
  #       soft: -1
  #       hard: -1
  #   healthcheck:
  #     test:
  #       [
  #         "CMD-SHELL",
  #         "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
  #       ]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 120

  # kibana:
  #   container_name: kibana
  #   depends_on:
  #     es01:
  #       condition: service_healthy
  #     es02:
  #       condition: service_healthy
  #   image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
  #   volumes:
  #     - certs:/usr/share/kibana/config/certs
  #     - kibanadata:/usr/share/kibana/data
  #   ports:
  #     - ${KIBANA_PORT}:5601
  #   environment:
  #     - SERVERNAME=kibana
  #     - ELASTICSEARCH_HOSTS=https://es01:9200
  #     - ELASTICSEARCH_USERNAME=kibana_system
  #     - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
  #     - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
  #   mem_limit: ${MEM_LIMIT}
  #   healthcheck:
  #     test:
  #       [
  #         "CMD-SHELL",
  #         "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
  #       ]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 120

# Kafka setup
  zookeeper:
    image: docker.io/bitnami/zookeeper:3.8
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    volumes:
      - zookeeper_data:/bitnami/zookeeper
  kafka-0:
    image: docker.io/bitnami/kafka:3.3
    container_name: kafka0
    ports:
      - 9092:9092
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_BROKER_ID=0
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - kafka_0_data:/bitnami/kafka
    depends_on:
      - zookeeper
  kafka-1:
    image: docker.io/bitnami/kafka:3.3
    container_name: kafka1
    ports:
      - 9093:9092
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_BROKER_ID=1
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - kafka_1_data:/bitnami/kafka
    depends_on:
      - zookeeper
  kafka-2:
    image: docker.io/bitnami/kafka:3.3
    container_name: kafka2
    ports:
      - 9094:9092
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_BROKER_ID=2
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - kafka_2_data:/bitnami/kafka
    depends_on:
      - zookeeper

volumes:
  hadoop_namenode:
  hadoop_datanode1:
  hadoop_datanode2:
  hadoop_historyserver:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
  # certs:
  #   driver: local
  # esdata01:
  #   driver: local
  # esdata02:
  #   driver: local
  kibanadata:
    driver: local
  zookeeper_data:
    driver: local
  kafka_0_data:
    driver: local
  kafka_1_data:
    driver: local
  kafka_2_data:
    driver: local
    